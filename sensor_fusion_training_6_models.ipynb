{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MwohvtboDQ3"
      },
      "source": [
        "# Libraries and Frameworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihx-fNJvgn7_"
      },
      "outputs": [],
      "source": [
        "#optional for google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdqIRk3wo2qn"
      },
      "outputs": [],
      "source": [
        "#install dependencies\n",
        "!pip install torchsummary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uudsafoXoZ26"
      },
      "outputs": [],
      "source": [
        "#standard libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "\n",
        "#augmentation\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import albumentations as A\n",
        "\n",
        "#torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, SubsetRandomSampler, DataLoader, random_split\n",
        "from torch.cuda.amp import GradScaler\n",
        "#from torchvision.transforms import v2\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR, ReduceLROnPlateau, ExponentialLR, CosineAnnealingLR\n",
        "from torchsummary import summary\n",
        "\n",
        "#import onnx\n",
        "import torch.onnx\n",
        "\n",
        "print(f'GPU on: {torch.cuda.is_available()}')\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)\n",
        "_today=datetime.today().strftime('%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DyjkZnIDgnHt"
      },
      "outputs": [],
      "source": [
        "#clear gpu cuda cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_yP6oR9gnHu"
      },
      "outputs": [],
      "source": [
        "#clone repo\n",
        "!git clone https://github.com/t0wgster/TonyWang_MasterThesis.git\n",
        "!cd TonyWang_MasterThesis && git pull\n",
        "\n",
        "#load in important functions\n",
        "from TonyWang_MasterThesis.functions_and_constants import *\n",
        "from TonyWang_MasterThesis.functions_and_constants import  _WH_RGB_HSI_Dataset\n",
        "from TonyWang_MasterThesis.visualisation_and_evaluation import *\n",
        "from TonyWang_MasterThesis.models import *\n",
        "from TonyWang_MasterThesis.post_processing import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5BdSa9-ZgnHw"
      },
      "outputs": [],
      "source": [
        "#optional\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZyI569ugnHw"
      },
      "outputs": [],
      "source": [
        "#make training deterministic, important for comparing different models\n",
        "seed_everything(91)\n",
        "VISUALIZE = True\n",
        "\n",
        "# Get the current date and time\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Format the current date as \"dd-mm-yyyy\"\n",
        "CURRENT_DATE = current_date.strftime(\"%d-%m-%Y\")\n",
        "\n",
        "print(\"Current date (dd-mm-yyyy format):\", CURRENT_DATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftSUByQhw7JY"
      },
      "source": [
        "# Initiate Dataset and Dataloaders for Training/Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bDZ9pa6jgnHx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oprjDIG0gnHy"
      },
      "outputs": [],
      "source": [
        "rgb_dir_train = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/train/rgb'\n",
        "hsi_dir_train = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/train/hsi'\n",
        "mask_dir_train = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/train/masks'\n",
        "\n",
        "rgb_dir_test = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/test/rgb'\n",
        "hsi_dir_test = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/test/hsi'\n",
        "mask_dir_test = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/test/masks'\n",
        "\n",
        "rgb_dir_val = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/val/rgb'\n",
        "hsi_dir_val = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/val/hsi'\n",
        "mask_dir_val = '/content/drive/MyDrive/Master/HSI/train-test-split-1106/split_resized_dataset_rgb_mask_hsi/val/masks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr-Rk6GBgnHy"
      },
      "outputs": [],
      "source": [
        "VAL_BATCH_SIZE=12\n",
        "TRAIN_BATCH_SIZE=12\n",
        "NUM_WORKERS=2\n",
        "\n",
        "#initialize train, test, val datasets\n",
        "train_dataset = _WH_RGB_HSI_Dataset(rgb_dir_train, hsi_dir_train, mask_dir_train,\n",
        "                                    transform = sf_transformation)\n",
        "test_dataset = _WH_RGB_HSI_Dataset(rgb_dir_test, hsi_dir_test, mask_dir_test,\n",
        "                                   transform = sf_transformation)\n",
        "val_dataset = _WH_RGB_HSI_Dataset(rgb_dir_val, hsi_dir_val, mask_dir_val,\n",
        "                                  transform = sf_transformation)\n",
        "\n",
        "#initialize train, test, val datasets with no augmentation\n",
        "train_dataset_final = _WH_RGB_HSI_Dataset(rgb_dir_train, hsi_dir_train, mask_dir_train,\n",
        "                                          transform = sf_no_transformation)\n",
        "test_dataset_final = _WH_RGB_HSI_Dataset(rgb_dir_test, hsi_dir_test, mask_dir_test,\n",
        "                                         transform = sf_no_transformation)\n",
        "val_dataset_final = _WH_RGB_HSI_Dataset(rgb_dir_val, hsi_dir_val, mask_dir_val,\n",
        "                                        transform = sf_no_transformation)\n",
        "\n",
        "generator1 = torch.Generator().manual_seed(42)\n",
        "\n",
        "print(f'Train Dataset Length: {len(train_dataset)}')\n",
        "print(f'Test Dataset Length: {len(test_dataset)}')\n",
        "print(f'Validation Dataset Length: {len(val_dataset)}')\n",
        "\n",
        "#initialize train, test, val dataloaders with no augmentation\n",
        "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2)\n",
        "train_loader_final = DataLoader(train_dataset_final, batch_size=TRAIN_BATCH_SIZE,\n",
        "                                shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE,\n",
        "                        shuffle=True, drop_last=True, num_workers=2)\n",
        "val_loader_final = DataLoader(val_dataset_final, batch_size=VAL_BATCH_SIZE,\n",
        "                              shuffle=True, drop_last=True, num_workers=2)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=2,\n",
        "                         shuffle=False, num_workers=2)\n",
        "test_loader_final = DataLoader(test_dataset_final, batch_size=2,\n",
        "                               shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiPBDLt0l4_8"
      },
      "source": [
        "# Check Augmentation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F73xB3qvggiS"
      },
      "outputs": [],
      "source": [
        "print('Legend:')\n",
        "for i, color in enumerate(COLORS_LONG):\n",
        "      print(f'{TXT_COLORS_LONG[i]} -> {CLASSES_LONG[i]}')\n",
        "print('\\033[0m - - - - -')\n",
        "\n",
        "for i in range(0, 20, 2):\n",
        "    print(i)\n",
        "    image, hsi_image, mask = train_dataset[i]\n",
        "    image2, hsi_image2, mask2 = train_dataset[i+1]\n",
        "\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    hsi_image = hsi_image.numpy().transpose((1, 2, 0))[:,:,0]\n",
        "\n",
        "    image2 = image2.numpy().transpose((1, 2, 0))\n",
        "    hsi_image2 = hsi_image2.numpy().transpose((1, 2, 0))[:,:,0]\n",
        "\n",
        "    #img_arr = np.asarray(image.permute(1,2,0))\n",
        "    mask_arr = np.asarray(mask)\n",
        "\n",
        "    #img_arr2 = np.asarray(image2.permute(1,2,0))\n",
        "    mask_arr2 = np.asarray(mask2)\n",
        "\n",
        "    fig, axs = plt.subplots(1,6, figsize=(16,16))\n",
        "    axs[0].imshow(image)\n",
        "    axs[1].imshow(hsi_image)\n",
        "    axs[2].imshow(mask_arr, cmap=cmap_long, norm=norm_long)\n",
        "\n",
        "    axs[3].imshow(image2)\n",
        "    axs[4].imshow(hsi_image2)\n",
        "    axs[5].imshow(mask_arr2, cmap=cmap_long, norm=norm_long)\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tr87M4bewSj"
      },
      "source": [
        "# Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HfVcFU4jgnHz"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.00037\n",
        "NUM_EPOCHS = 5\n",
        "NUM_EPOCHS_FINAL = 3\n",
        "PATIENCE = 0\n",
        "\n",
        "WEIGHTS = torch.tensor([1.0 ,1.0, 3.0 ,10.0\n",
        "                        ,25.0 ,10.0 ,10.0\n",
        "                        ,12.0 ,1.0 ,10.0]).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-DPzTVvpN00"
      },
      "source": [
        "# Data Level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4HUD6RYTo12"
      },
      "source": [
        "# Training Parameters - Data Level Fusion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_LGQ756hGZj"
      },
      "outputs": [],
      "source": [
        "sf_model = unet_model_gelu_data_level_fusion(in_channels_hsi=6, out_channels=10).to(DEVICE)\n",
        "\n",
        "\n",
        "ce_loss_fn = nn.CrossEntropyLoss(weight=WEIGHTS)\n",
        "dice_loss_fn=DiceLoss(n_classes=10)\n",
        "\n",
        "optimizer = Adam(sf_model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "scheduler = ExponentialLR(optimizer, last_epoch=-1, gamma=0.9)\n",
        "source = 'sf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBXR403HgnH0"
      },
      "outputs": [],
      "source": [
        "summary(sf_model, input_size=[(3,384,320), (6,384,320)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA2K1qtwXFCV"
      },
      "source": [
        "# Model Training Data Level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJK5jNCnXEi9"
      },
      "outputs": [],
      "source": [
        "avg_train_loss_list=[]\n",
        "avg_val_loss_list=[]\n",
        "avg_train_iou_list=[]\n",
        "avg_val_iou_list=[]\n",
        "softmax = nn.Softmax(dim=1)\n",
        "data_level_name = 'DataLevel'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4lTicZVjgij"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "dl_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(sf_model, train_loader, val_loader_final, NUM_EPOCHS,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=PATIENCE, model_name=data_level_name,\n",
        "                                                                            data_source = source)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10XqjGd1gnH1"
      },
      "outputs": [],
      "source": [
        "dl_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(dl_model_trained, train_loader_final, val_loader_final, NUM_EPOCHS_FINAL,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=0, model_name=data_level_name,\n",
        "                                                                            data_source = source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYsQV9JIgnH2"
      },
      "outputs": [],
      "source": [
        "#plot_range = range(NUM_EPOCHS+NUM_EPOCHS_FINAL)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax.plot(range(len(avg_train_loss_list)), avg_train_loss_list, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "\n",
        "# Create a twin Axes sharing the xaxis\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(range(len(avg_val_loss_list)), avg_val_loss_list, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Training Loss', color='blue')\n",
        "ax2.set_ylabel('Validation Loss', color='orange')\n",
        "ax.set_title('Training vs Validation Loss')\n",
        "\n",
        "# Show legend for both axes\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp416no1oq2U"
      },
      "source": [
        "# Evaluation - Data Level Fusion Model - Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4WhKXuSgnH2"
      },
      "outputs": [],
      "source": [
        "test_ds_union, test_ds_intersection, test_ds_numerator, test_ds_denominator, iou_image_pixelwise, dice_image_pixelwise = capture_model_metrics_pixelwise_and_confusion_matrix_sf(dl_model_trained, test_dataset_final, data_source='sf', visualize=VISUALIZE, mask_shape = (384, 320))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlXtXlXTgnH2"
      },
      "outputs": [],
      "source": [
        "calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True, file_name=data_level_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOni7OaapRB-"
      },
      "source": [
        "# Feature Level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON-szZKSgnH2"
      },
      "source": [
        "# Training Parameters - Feature Level Fusion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxjztZqagnH2"
      },
      "outputs": [],
      "source": [
        "sf_model = unet_model_gelu_feature_level_fusion(in_channels_hsi=6, out_channels=10).to(DEVICE)\n",
        "\n",
        "ce_loss_fn = nn.CrossEntropyLoss(weight=WEIGHTS)\n",
        "dice_loss_fn=DiceLoss(n_classes=10)\n",
        "\n",
        "optimizer = Adam(sf_model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "scheduler = ExponentialLR(optimizer, last_epoch=-1, gamma=0.9)\n",
        "source = 'sf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQsr_yaognH3"
      },
      "outputs": [],
      "source": [
        "summary(sf_model, input_size=[(3,384,320), (6,384,320)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRrXq8IjpJnk"
      },
      "source": [
        "# Model Training Feature Level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUJ9YA5vgnH3"
      },
      "outputs": [],
      "source": [
        "avg_train_loss_list=[]\n",
        "avg_val_loss_list=[]\n",
        "avg_train_iou_list=[]\n",
        "avg_val_iou_list=[]\n",
        "softmax = nn.Softmax(dim=1)\n",
        "feature_level_name = 'FeatureLevel'\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "fl_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(sf_model, train_loader, val_loader_final, NUM_EPOCHS,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=PATIENCE, model_name=feature_level_name,\n",
        "                                                                            data_source = source)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4AnqYOvgnH3"
      },
      "outputs": [],
      "source": [
        "fl_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(fl_model_trained, train_loader_final, val_loader_final, NUM_EPOCHS_FINAL,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=0, model_name=feature_level_name,\n",
        "                                                                            data_source = source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9E0HgxLgnH3"
      },
      "outputs": [],
      "source": [
        "#plot_range = range(NUM_EPOCHS+NUM_EPOCHS_FINAL)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax.plot(range(len(avg_train_loss_list)), avg_train_loss_list, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "\n",
        "# Create a twin Axes sharing the xaxis\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(range(len(avg_val_loss_list)), avg_val_loss_list, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Training Loss', color='blue')\n",
        "ax2.set_ylabel('Validation Loss', color='orange')\n",
        "ax.set_title('Training vs Validation Loss')\n",
        "\n",
        "# Show legend for both axes\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiX3YP2dpXsp"
      },
      "source": [
        "# Evaluation - Feature Level Fusion Model - Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azdYCyY7gnH4"
      },
      "outputs": [],
      "source": [
        "test_ds_union, test_ds_intersection, test_ds_numerator, test_ds_denominator, iou_image_pixelwise, dice_image_pixelwise = capture_model_metrics_pixelwise_and_confusion_matrix_sf(fl_model_trained, test_dataset_final, data_source='sf', visualize=VISUALIZE, mask_shape = (384, 320))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E6LK03WgnH4"
      },
      "outputs": [],
      "source": [
        "calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True, file_name=feature_level_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lofxw0sugnH4"
      },
      "source": [
        "# RGB - Unet Classic/Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzvcCa0aph4v"
      },
      "source": [
        "# Training Parameters - RGB Unet Classic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EFPOal1gnH4"
      },
      "outputs": [],
      "source": [
        "classic_model = unet_model_classic(out_channels=10).to(DEVICE)\n",
        "\n",
        "ce_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = Adam(classic_model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "scheduler = ExponentialLR(optimizer, last_epoch=-1, gamma=0.9)\n",
        "source = 'rgb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSgRix-6gnH5"
      },
      "outputs": [],
      "source": [
        "summary(classic_model, (3, 384, 320))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG_Ih8PNpprj"
      },
      "source": [
        "# Model Training RGB Unet Classic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hBzhY-fgnH5"
      },
      "outputs": [],
      "source": [
        "avg_train_loss_list=[]\n",
        "avg_val_loss_list=[]\n",
        "avg_train_iou_list=[]\n",
        "avg_val_iou_list=[]\n",
        "softmax = nn.Softmax(dim=1)\n",
        "classic_name = 'Classic'\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "classic_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training(classic_model, train_loader, val_loader_final, NUM_EPOCHS,\n",
        "                                                                            ce_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=PATIENCE, model_name=classic_name,\n",
        "                                                                            data_source = source)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MfTPg8vgnH5"
      },
      "outputs": [],
      "source": [
        "classic_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training(classic_model_trained, train_loader_final, val_loader_final, NUM_EPOCHS_FINAL,\n",
        "                                                                            ce_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=0, model_name=classic_name,\n",
        "                                                                            data_source = source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvdBLcR4gnH5"
      },
      "outputs": [],
      "source": [
        "#plot final training and validation loss\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax.plot(range(len(avg_train_loss_list)), avg_train_loss_list, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "\n",
        "# Create a twin Axes sharing the xaxis\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(range(len(avg_val_loss_list)), avg_val_loss_list, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Training Loss', color='blue')\n",
        "ax2.set_ylabel('Validation Loss', color='orange')\n",
        "ax.set_title('Training vs Validation Loss')\n",
        "\n",
        "# Show legend for both axes\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPwBxRqmps2V"
      },
      "source": [
        "# Evaluation - RGB Unet Classic Model - Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLCM7fJcgnH6"
      },
      "outputs": [],
      "source": [
        "# evaluate model and visualize model outcome, optionally project confusion matrix\n",
        "test_ds_union, test_ds_intersection, test_ds_numerator, test_ds_denominator, iou_image_pixelwise, dice_image_pixelwise = capture_model_metrics_pixelwise_and_confusion_matrix_sf(classic_model_trained, test_dataset_final, data_source='rgb', visualize=VISUALIZE, mask_shape = (384, 320))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFW9bVA7gnH6"
      },
      "outputs": [],
      "source": [
        "# calculate average model metrics\n",
        "calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True, file_name=classic_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5ujHanngnH6"
      },
      "source": [
        "# RGB - GELU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHzmgsHCp3xy"
      },
      "source": [
        "# Training Parameters - RGB GELU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vZn2IE7_gnH6"
      },
      "outputs": [],
      "source": [
        "# initiate GEU model with 10 output classes and project model to CUDA\n",
        "gelu_model = unet_model_gelu(out_channels=10).to(DEVICE)\n",
        "\n",
        "# define CE and Dice loss\n",
        "ce_loss_fn = nn.CrossEntropyLoss(weight=WEIGHTS)\n",
        "dice_loss_fn=DiceLoss(n_classes=10)\n",
        "\n",
        "# define Adam optimizer and learning rate\n",
        "optimizer = Adam(gelu_model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# optional scheduler\n",
        "scheduler = ExponentialLR(optimizer, last_epoch=-1, gamma=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SRGnq41gnH7"
      },
      "outputs": [],
      "source": [
        "#show a model summary\n",
        "summary(gelu_model, (3, 384, 320))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOClnpgyp6hV"
      },
      "source": [
        "# Training RGB GELU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNoaWPDJgnH7"
      },
      "outputs": [],
      "source": [
        "#lists to store train and validation loss, for plotting purposes\n",
        "avg_train_loss_list=[]\n",
        "avg_val_loss_list=[]\n",
        "avg_train_iou_list=[]\n",
        "avg_val_iou_list=[]\n",
        "source = 'rgb'\n",
        "gelu_name = 'Gelu'\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Training for defined number of epochs\n",
        "gelu_trained_model, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(gelu_model, train_loader, val_loader_final, NUM_EPOCHS,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=PATIENCE, model_name=gelu_name,\n",
        "                                                                            data_source = source)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')\n",
        "\n",
        "# Training for additional 3 epochs with no augmentations\n",
        "gelu_trained_model, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(gelu_trained_model, train_loader_final, val_loader_final, NUM_EPOCHS_FINAL,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=0, model_name=gelu_name,\n",
        "                                                                            data_source = source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLRZC2HzgnH7"
      },
      "outputs": [],
      "source": [
        "#plot_range = range(NUM_EPOCHS+NUM_EPOCHS_FINAL)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax.plot(range(len(avg_train_loss_list)), avg_train_loss_list, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "\n",
        "# Create a twin Axes sharing the xaxis\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(range(len(avg_val_loss_list)), avg_val_loss_list, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Training Loss', color='blue')\n",
        "ax2.set_ylabel('Validation Loss', color='orange')\n",
        "ax.set_title('Training vs Validation Loss')\n",
        "\n",
        "# Show legend for both axes\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ1wOd6zp-KL"
      },
      "source": [
        "# Evaluation - RGB GELU Model - Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkDOs3AugnH8"
      },
      "outputs": [],
      "source": [
        "test_ds_union, test_ds_intersection, test_ds_numerator, test_ds_denominator, iou_image_pixelwise, dice_image_pixelwise = capture_model_metrics_pixelwise_and_confusion_matrix_sf(gelu_trained_model,\n",
        "                                                                                                                                                                                 test_dataset_final,\n",
        "                                                                                                                                                                                 data_source='rgb',\n",
        "                                                                                                                                                                                 visualize = VISUALIZE,\n",
        "                                                                                                                                                                                 mask_shape = (384, 320))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZkQkndSgnH9"
      },
      "outputs": [],
      "source": [
        "calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True, file_name=gelu_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPKT-EBAgnH9"
      },
      "source": [
        "# RGB - ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNkkuw2qKXM"
      },
      "source": [
        "# Training Parameters - RGB ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys7kxuLPgnH9"
      },
      "outputs": [],
      "source": [
        "resnet_model = UNetWithResnet50Encoder(n_classes=10).to(DEVICE)\n",
        "\n",
        "ce_loss_fn = nn.CrossEntropyLoss(weight=WEIGHTS)\n",
        "dice_loss_fn=DiceLoss(n_classes=10)\n",
        "\n",
        "optimizer = Adam(resnet_model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "scheduler = ExponentialLR(optimizer, last_epoch=-1, gamma=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0k4RzAXgnH9"
      },
      "outputs": [],
      "source": [
        "summary(resnet_model, (3, 384, 320))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7TozebrqOli"
      },
      "source": [
        "# Training RGB ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsfliIBagnH9"
      },
      "outputs": [],
      "source": [
        "avg_train_loss_list=[]\n",
        "avg_val_loss_list=[]\n",
        "avg_train_iou_list=[]\n",
        "avg_val_iou_list=[]\n",
        "softmax = nn.Softmax(dim=1)\n",
        "resnet_name = 'ResNet'\n",
        "source = 'rgb'\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "resnet_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(resnet_model, train_loader, val_loader_final, NUM_EPOCHS,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=PATIENCE, model_name=resnet_name,\n",
        "                                                                            data_source = source)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcxBUGZ4gnH9"
      },
      "outputs": [],
      "source": [
        "resnet_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(resnet_model_trained, train_loader_final, val_loader_final, NUM_EPOCHS_FINAL,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=0, model_name=resnet_name,\n",
        "                                                                            data_source = source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktmGh0PvgnH9"
      },
      "outputs": [],
      "source": [
        "#plot_range = range(NUM_EPOCHS+NUM_EPOCHS_FINAL)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax.plot(range(len(avg_train_loss_list)), avg_train_loss_list, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "\n",
        "# Create a twin Axes sharing the xaxis\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(range(len(avg_val_loss_list)), avg_val_loss_list, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Training Loss', color='blue')\n",
        "ax2.set_ylabel('Validation Loss', color='orange')\n",
        "ax.set_title('Training vs Validation Loss')\n",
        "\n",
        "# Show legend for both axes\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZ-IdJhqRVp"
      },
      "source": [
        "# Evaluation - RGB ResNet Model - Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZxKdKW2gnH9"
      },
      "outputs": [],
      "source": [
        "test_ds_union, test_ds_intersection, test_ds_numerator, test_ds_denominator, iou_image_pixelwise, dice_image_pixelwise = capture_model_metrics_pixelwise_and_confusion_matrix_sf(resnet_model_trained, test_dataset_final, data_source='rgb', visualize = VISUALIZE, mask_shape = (384, 320))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdRnc6TIgnH9"
      },
      "outputs": [],
      "source": [
        "calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True, file_name=resnet_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHJLJw1ignH_"
      },
      "source": [
        "# HSI - GELU PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaB8y11PqY_M"
      },
      "source": [
        "# Training Parameters - HSI GELU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz-2YajjgnH_"
      },
      "outputs": [],
      "source": [
        "hsi_unet_pca_model = hsi_unet_model_gelu_pca(6).to(DEVICE)\n",
        "\n",
        "ce_loss_fn = nn.CrossEntropyLoss(weight=WEIGHTS)\n",
        "dice_loss_fn=DiceLoss(n_classes=10)\n",
        "\n",
        "optimizer = Adam(hsi_unet_pca_model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "scheduler = ExponentialLR(optimizer, last_epoch=-1, gamma=0.9)\n",
        "source='hsi'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xq1Qf5NgnH_"
      },
      "outputs": [],
      "source": [
        "summary(hsi_unet_pca_model, (6, 384, 320))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSX6suTLqhm7"
      },
      "source": [
        "# Training HSI GELU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVn0KYqcgnH_"
      },
      "outputs": [],
      "source": [
        "avg_train_loss_list=[]\n",
        "avg_val_loss_list=[]\n",
        "avg_train_iou_list=[]\n",
        "avg_val_iou_list=[]\n",
        "softmax = nn.Softmax(dim=1)\n",
        "hsi_unet_pca_name = 'HSI_PCA'\n",
        "source = 'hsi'\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "hsi_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(hsi_unet_pca_model, train_loader, val_loader_final, NUM_EPOCHS,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=PATIENCE, model_name=hsi_unet_pca_name,\n",
        "                                                                            data_source = source)\n",
        "\n",
        "end = time.time()\n",
        "print(f'Time taken: {end - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmD0DNubgnH_"
      },
      "outputs": [],
      "source": [
        "hsi_model_trained, loss, avg_train_loss_list, avg_val_loss_list = sf_model_training_multiloss(hsi_model_trained, train_loader_final, val_loader_final, NUM_EPOCHS_FINAL,\n",
        "                                                                            ce_loss_fn, dice_loss_fn, optimizer, scaler, scheduler,\n",
        "                                                                            avg_train_loss_list, avg_val_loss_list,\n",
        "                                                                            TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
        "                                                                            activate_scheduler=False, patience=0, model_name=hsi_unet_pca_name,\n",
        "                                                                            data_source = source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0eHIAAtgnH_"
      },
      "outputs": [],
      "source": [
        "#plot_range = range(NUM_EPOCHS+NUM_EPOCHS_FINAL)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax.plot(range(len(avg_train_loss_list)), avg_train_loss_list, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "\n",
        "# Create a twin Axes sharing the xaxis\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(range(len(avg_val_loss_list)), avg_val_loss_list, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Training Loss', color='blue')\n",
        "ax2.set_ylabel('Validation Loss', color='orange')\n",
        "ax.set_title('Training vs Validation Loss')\n",
        "\n",
        "# Show legend for both axes\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz10eofwqnGD"
      },
      "source": [
        "# Evaluation - HSI GELU Model - Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTh7jCxugnH_"
      },
      "outputs": [],
      "source": [
        "test_ds_union, test_ds_intersection, test_ds_numerator, test_ds_denominator, iou_image_pixelwise, dice_image_pixelwise = capture_model_metrics_pixelwise_and_confusion_matrix_sf(hsi_model_trained, test_dataset_final, data_source='hsi', visualize = VISUALIZE, mask_shape = (384, 320))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZyNxtmQgnH_"
      },
      "outputs": [],
      "source": [
        "calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True, file_name=hsi_unet_pca_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhPSZVhR0hBG"
      },
      "source": [
        "# Post Processing pre Argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcSlvypkxbI4"
      },
      "outputs": [],
      "source": [
        "test_ds_union = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_intersection = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_numerator = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_denominator = [0,0,0,0,0,0,0,0,0,0]\n",
        "kernel_size = [1,12,12,1,50,8,6,10,1,4]*2\n",
        "smooth=1e-8\n",
        "mask_shape = (384,320)\n",
        "\n",
        "def probability_based_kernel_post_processing(model, smooth, dataset, mask_shape, kernel_size):\n",
        "\n",
        "    #create array to capture all ground truth and predictions to calculate final IoU and Dice Score at the end\n",
        "    ground_truth_all_images=np.zeros((mask_shape[0], mask_shape[1], len(test_dataset_final)))\n",
        "    prediction_all_images=np.zeros((mask_shape[0], mask_shape[1], len(test_dataset_final)))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for n, batch in enumerate(dataset):\n",
        "\n",
        "            #empty numpy mask to fit the one hot encoded classes\n",
        "            pp_one_hot_pred_masks = np.zeros((384,320, 10))\n",
        "\n",
        "            rgb_img, hsi_img, mask = batch\n",
        "\n",
        "            #predict imgs in dataset\n",
        "            rgb_img = rgb_img.to(DEVICE).unsqueeze(0)\n",
        "            mask = mask.to(DEVICE)\n",
        "            softmax = nn.Softmax(dim=1)\n",
        "\n",
        "            #predicted probabilities\n",
        "            preds = softmax(model(rgb_img.float())).to('cpu').squeeze(0).permute(1,2,0)\n",
        "            preds_np = preds.numpy()\n",
        "\n",
        "            #combined masks for comparison\n",
        "            preds_argmax = torch.argmax(preds, axis=-1).to('cpu').squeeze(0)\n",
        "\n",
        "            start = time.time()\n",
        "\n",
        "            # individual kernels for each defect class\n",
        "            for i in range(9, 2, -1):\n",
        "                kernel = np.ones((kernel_size[i],kernel_size[i]),np.uint8)\n",
        "                radius = int(kernel_size[i]/2)\n",
        "\n",
        "                #elliptical kernel size\n",
        "                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * radius + 1, 2 * radius + 1))\n",
        "\n",
        "                #closing operation\n",
        "                pp_one_hot_pred_masks[:,:,i] = cv2.morphologyEx(preds_np[:,:,i], cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "            # individual kernels for each background, fillet front and back class\n",
        "            for i in range(2, -1, -1):\n",
        "                kernel = np.ones((kernel_size[i],kernel_size[i]),np.uint8)\n",
        "                radius = int(kernel_size[i]/2)\n",
        "                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * radius + 1, 2 * radius + 1))\n",
        "\n",
        "                #dilation operation\n",
        "                pp_one_hot_pred_masks[:,:,i] = cv2.dilate(preds_np[:,:,i], kernel)\n",
        "\n",
        "            end = time.time()\n",
        "            print(f'Time: {end - start}')\n",
        "\n",
        "            # convert back to torch because evaluation functions only work with torch tensors\n",
        "            pp_one_hot_pred_masks = torch.from_numpy(pp_one_hot_pred_masks).to('cpu')\n",
        "\n",
        "            # combine post processed masks\n",
        "            single_mask = np.argmax(pp_one_hot_pred_masks, axis=-1)\n",
        "\n",
        "            # add current mask and prediction to stacked array for\n",
        "            prediction_all_images[:,:,n] = single_mask\n",
        "            ground_truth_all_images[:,:,n] = mask.to('cpu').numpy()\n",
        "\n",
        "            #calculate dice and iou score for calculating final IoU and Dice Score at the end\n",
        "            is_list, u_list=intersection_and_union_all_classes(mask, single_mask, SINGLE_PREDICTION=True)\n",
        "            n_list, d_list=dice_values_all_classes(mask, single_mask, SINGLE_PREDICTION=True)\n",
        "\n",
        "            #visualize predictions vs ground truth\n",
        "            visualize_prediction_vs_ground_truth_overlay_all_sources_postprocessing(rgb_img.squeeze(0), hsi_img.squeeze(0), mask, preds_argmax.squeeze(0), single_mask, 'rgb')\n",
        "\n",
        "            #print iou and dice score for each individual image\n",
        "            print('IOU')\n",
        "            for i in range(len(NUM_UNIQUE_VALUES_LONG)):\n",
        "                if is_ground_truth_empty(mask)[i] and is_prediction_empty(single_mask)[i]:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: Empty')\n",
        "                else:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: {is_list[i]/(u_list[i]+smooth):.4f}')\n",
        "                    #tracking class average of iou across all images\n",
        "                    test_ds_union[i] += u_list[i]\n",
        "                    test_ds_intersection[i] += is_list[i]\n",
        "\n",
        "            print(TXT_COLORS_LONG_COLOR_ONLY[0]+ 'x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x')\n",
        "            print('Dice')\n",
        "            for i in range(len(NUM_UNIQUE_VALUES_LONG)):\n",
        "                if is_ground_truth_empty(mask)[i] and is_prediction_empty(single_mask)[i]:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: Empty')\n",
        "                else:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: {n_list[i]/(d_list[i]+smooth):.4f}')\n",
        "                    #tracking class average of iou across all images\n",
        "                    test_ds_numerator[i] += n_list[i]\n",
        "                    test_ds_denominator[i] += d_list[i]\n",
        "\n",
        "                print(TXT_COLORS_LONG_COLOR_ONLY[0])\n",
        "\n",
        "    #evaluate overall model\n",
        "    calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True)\n",
        "\n",
        "probability_based_kernel_post_processing(gelu_trained_model, smooth, test_dataset_final, mask_shape, kernel_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GafBf4Tx5pFH"
      },
      "source": [
        "# Post Processing after argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ5exr6Sy41E"
      },
      "outputs": [],
      "source": [
        "test_ds_union = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_intersection = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_numerator = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_denominator = [0,0,0,0,0,0,0,0,0,0]\n",
        "kernel_size = [1,20,20,1,50,8,6,16,1,4]\n",
        "smooth=1e-8\n",
        "mask_shape = (384,320)\n",
        "\n",
        "def region_based_kernel_post_processing(model, smooth, dataset, mask_shape, kernel_size):\n",
        "\n",
        "    #create array to capture all ground truth and predictions to calculate final IoU and Dice Score at the end\n",
        "    ground_truth_all_images=np.zeros((mask_shape[0], mask_shape[1], len(dataset)))\n",
        "    prediction_all_images=np.zeros((mask_shape[0], mask_shape[1], len(dataset)))\n",
        "    pp_one_hot_pred_masks = np.zeros((384,320, 10),np.uint8)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for n, batch in enumerate(dataset):\n",
        "            rgb_img, hsi_img, mask = batch\n",
        "\n",
        "            rgb_img = rgb_img.to(DEVICE).unsqueeze(0)\n",
        "            mask = mask.to(DEVICE)\n",
        "            softmax = nn.Softmax(dim=1)\n",
        "            preds = torch.argmax(softmax(model(rgb_img.float())),axis=1).to('cpu').squeeze(0)\n",
        "\n",
        "            #one hot encoding of mask after argmax\n",
        "            one_hot_pred_masks=F.one_hot(preds.to(torch.int64), num_classes=10).to(DEVICE)\n",
        "\n",
        "            # individual kernels for each defect class\n",
        "            for i in range(9, 2, -1):\n",
        "                kernel = np.ones((kernel_size[i],kernel_size[i]),np.uint8)\n",
        "                pp_one_hot_pred_masks[:,:,i] = cv2.morphologyEx(one_hot_pred_masks[:,:,i].to('cpu').numpy().astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "            # individual kernels for each background, fillet front and back class\n",
        "            for i in range(2, -1, -1):\n",
        "                kernel = np.ones((kernel_size[i],kernel_size[i]),np.uint8)\n",
        "                pp_one_hot_pred_masks[:,:,i] = cv2.morphologyEx(one_hot_pred_masks[:,:,i].to('cpu').numpy().astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "            #give defect class and fillet front and back more weight than background class\n",
        "            pp_one_hot_pred_masks[:,:,1:3] = pp_one_hot_pred_masks[:,:,1:3]*2\n",
        "            pp_one_hot_pred_masks[:,:,3:10] = pp_one_hot_pred_masks[:,:,3:10]*3\n",
        "\n",
        "            #combine mask\n",
        "            single_mask_array = np.argmax(pp_one_hot_pred_masks, axis=-1)\n",
        "            single_mask = torch.from_numpy(single_mask_array)\n",
        "\n",
        "            # add current mask and prediction to stacked array for confusion matrix\n",
        "            prediction_all_images[:,:,n] = single_mask_array\n",
        "            ground_truth_all_images[:,:,n] = mask.to('cpu').numpy()\n",
        "\n",
        "            #calculate dice and iou score for calculating final IoU and Dice Score at the end\n",
        "            is_list, u_list=intersection_and_union_all_classes(mask, single_mask, SINGLE_PREDICTION=True)\n",
        "            n_list, d_list=dice_values_all_classes(mask, single_mask, SINGLE_PREDICTION=True)\n",
        "\n",
        "            #visualize predictions vs ground truth\n",
        "            visualize_prediction_vs_ground_truth_overlay_all_sources_postprocessing(rgb_img.squeeze(0), hsi_img.squeeze(0), mask, preds.squeeze(0), single_mask, 'rgb')\n",
        "\n",
        "            #print iou and dice score for each individual image\n",
        "            print('IOU')\n",
        "            for i in range(len(NUM_UNIQUE_VALUES_LONG)):\n",
        "                if is_ground_truth_empty(mask)[i] and is_prediction_empty(single_mask)[i]:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: Empty')\n",
        "                else:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: {is_list[i]/(u_list[i]+smooth):.4f}')\n",
        "                    #tracking class average of iou across all images\n",
        "                    test_ds_union[i] += u_list[i]\n",
        "                    test_ds_intersection[i] += is_list[i]\n",
        "\n",
        "            print(TXT_COLORS_LONG_COLOR_ONLY[0]+ 'x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x')\n",
        "            print('Dice')\n",
        "            for i in range(len(NUM_UNIQUE_VALUES_LONG)):\n",
        "                if is_ground_truth_empty(mask)[i] and is_prediction_empty(single_mask)[i]:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: Empty')\n",
        "                else:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: {n_list[i]/(d_list[i]+smooth):.4f}')\n",
        "                    #tracking class average of iou across all images\n",
        "                    test_ds_numerator[i] += n_list[i]\n",
        "                    test_ds_denominator[i] += d_list[i]\n",
        "\n",
        "            print(TXT_COLORS_LONG_COLOR_ONLY[0])\n",
        "\n",
        "    calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True)\n",
        "\n",
        "region_based_kernel_post_processing(gelu_trained_model, smooth, test_dataset_final, mask_shape, kernel_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKGOrUAWgyBm"
      },
      "source": [
        "# CRF-based Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git"
      ],
      "metadata": {
        "id": "zDx2Udk40pJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkd1UID7xbGP"
      },
      "outputs": [],
      "source": [
        "#!pip install pydensecrf\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral, create_pairwise_gaussian\n",
        "\n",
        "test_ds_union = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_intersection = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_numerator = [0,0,0,0,0,0,0,0,0,0]\n",
        "test_ds_denominator = [0,0,0,0,0,0,0,0,0,0]\n",
        "mask_shape = (384,320)\n",
        "smooth=1e-8\n",
        "\n",
        "theta_alpha = 20\n",
        "theta_beta = 15\n",
        "theta_gamma = 6\n",
        "\n",
        "def crf_based_post_processing(model, smooth, dataset, mask_shape, theta_a, theta_b, theta_g):\n",
        "\n",
        "    #create array to capture all ground truth and predictions to calculate final IoU and Dice Score at the end\n",
        "    ground_truth_all_images=np.zeros((mask_shape[0], mask_shape[1], len(test_dataset_final)))\n",
        "    prediction_all_images=np.zeros((mask_shape[0], mask_shape[1], len(test_dataset_final)))\n",
        "    pp_one_hot_pred_masks = np.zeros((384,320, 10),np.uint8)\n",
        "\n",
        "    #model inference\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for n, batch in enumerate(test_dataset_final):\n",
        "            rgb_img, hsi_img, mask = batch\n",
        "\n",
        "            rgb_img = rgb_img.to(DEVICE).unsqueeze(0)\n",
        "            mask = mask.to(DEVICE)\n",
        "            softmax = nn.Softmax(dim=1)\n",
        "            preds = torch.argmax(softmax(model(rgb_img.float())),axis=1).to('cpu').squeeze(0)\n",
        "\n",
        "            #convert original img and annotated img into numpy arrays\n",
        "            original_image=rgb_img.to('cpu').squeeze().permute(1,2,0).numpy()\n",
        "            annotated_image=preds.to('cpu').numpy().astype(np.uint32)\n",
        "\n",
        "            #from here: code snippets from git@github.com:lucasb-eyer/pydensecrf.git\n",
        "            #and from here: code snippets from git@github.com:dhawan98/Post-Processing-of-Image-Segmentation-using-CRF.git\n",
        "            #number of classes in dataset\n",
        "            n_labels_a = 10\n",
        "\n",
        "            #flatten segmentation mask\n",
        "            labels_a = annotated_image.flatten()\n",
        "\n",
        "            #Setting up the CRF model\n",
        "            d = dcrf.DenseCRF2D(original_image.shape[1], original_image.shape[0], n_labels_a)\n",
        "\n",
        "            # get unary potentials (neg log probability)\n",
        "            U = unary_from_labels(labels_a, n_labels_a, gt_prob=0.90, zero_unsure=False)\n",
        "\n",
        "            #calculate Gibbs energy\n",
        "            d.setUnaryEnergy(U)\n",
        "\n",
        "            # This adds the color-independent term, features are the locations only.\n",
        "            # smoothing kernel\n",
        "            d.addPairwiseGaussian(sxy=(theta_gamma, theta_gamma), compat=3, kernel=dcrf.DIAG_KERNEL,\n",
        "                              normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "\n",
        "            # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
        "            # appearance kernel\n",
        "            d.addPairwiseBilateral(sxy=(theta_alpha, theta_alpha), srgb=(theta_beta, theta_beta, theta_beta), rgbim=original_image.astype(np.uint8),\n",
        "                               compat=10,\n",
        "                               kernel=dcrf.DIAG_KERNEL,\n",
        "                               normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "\n",
        "            #Run CRF model inference for x steps\n",
        "            Q = d.inference(1)\n",
        "\n",
        "            # Find out the most probable class for each pixel.\n",
        "            MAP = np.argmax(Q, axis=0)\n",
        "\n",
        "            # Convert the MAP (labels) back to the corresponding colors and save the image.\n",
        "            post_processed_mask=MAP.reshape(annotated_image.shape)\n",
        "\n",
        "            ####\n",
        "            #code snippets from github repos end here\n",
        "\n",
        "            #convert mask back to torch tensor for evaluating purposes\n",
        "            single_mask = torch.from_numpy(post_processed_mask)\n",
        "\n",
        "            #calculate dice and iou score for calculating final IoU and Dice Score at the end\n",
        "            is_list, u_list=intersection_and_union_all_classes(mask, single_mask, SINGLE_PREDICTION=True)\n",
        "            n_list, d_list=dice_values_all_classes(mask, single_mask, SINGLE_PREDICTION=True)\n",
        "\n",
        "            #visualize predictions vs ground truth\n",
        "            visualize_prediction_vs_ground_truth_overlay_all_sources_postprocessing(rgb_img.squeeze(0), hsi_img.squeeze(0), mask, preds.squeeze(0), single_mask, 'rgb')\n",
        "\n",
        "            #print iou and dice score for each individual image\n",
        "            print('IOU')\n",
        "            for i in range(len(NUM_UNIQUE_VALUES_LONG)):\n",
        "                if is_ground_truth_empty(mask)[i] and is_prediction_empty(single_mask)[i]:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: Empty')\n",
        "                else:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: {is_list[i]/(u_list[i]+smooth):.4f}')\n",
        "                    #tracking class average of iou across all images\n",
        "                    test_ds_union[i] += u_list[i]\n",
        "                    test_ds_intersection[i] += is_list[i]\n",
        "\n",
        "            print(TXT_COLORS_LONG_COLOR_ONLY[0]+ 'x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x')\n",
        "            print('Dice')\n",
        "            for i in range(len(NUM_UNIQUE_VALUES_LONG)):\n",
        "                if is_ground_truth_empty(mask)[i] and is_prediction_empty(single_mask)[i]:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: Empty')\n",
        "                else:\n",
        "                    print(f'{TXT_COLORS_LONG_COLOR_ONLY[i]} - {CLASSES_LONG[i]}: {n_list[i]/(d_list[i]+smooth):.4f}')\n",
        "                    #tracking class average of iou across all images\n",
        "                    test_ds_numerator[i] += n_list[i]\n",
        "                    test_ds_denominator[i] += d_list[i]\n",
        "\n",
        "            print(TXT_COLORS_LONG_COLOR_ONLY[0])\n",
        "\n",
        "        calculate_model_metrics(test_ds_intersection, test_ds_union, test_ds_numerator, test_ds_denominator, defects_only=True)\n",
        "\n",
        "crf_based_post_processing(gelu_trained_model, smooth, test_dataset_final, mask_shape, theta_alpha, theta_beta, theta_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE3UwiY4xbD1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hO7nqB6wztST"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5155186,
          "sourceId": 8616507,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5184721,
          "sourceId": 8654841,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}